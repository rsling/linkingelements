% !Rnw root = ../leglossa.Rnw
<<setupcorpus, cache=FALSE, include=FALSE, results='asis'>>=
opts_knit$set(self.contained=FALSE)
@

\section{Corpus study}
\label{sec:corpusstudy}

\subsection{Queries}
\label{sec:queries}

As explained in Section~\ref{sec:linkingelementsingerman}, we try to determine whether two distinct factors increase the probability that N1 in an N1+N2 compound occurs with a pluralic linking element given that N1 alternates between a pluralic and a non-pluralic link.
The first potential factor is a plural on the whole compound (formally on N2).
The second factor is whether a semantic relation between N1 and N2 holds which forces N1 to have plural semantics.
Therefore, we had to manually annotate corpus exemplars containing N+N compounds for whether they are plurals and whether a plural-enforcing semantic relation holds between N1 and N2.
Before turning to this annotation process in Section~\ref{sec:annotation}, this section describes how we extracted and prepared a concordance for the manual annotation.

First, a selection of N1s was required which represents the population of N1s well with regard to their productivities with PL and NPL, and a set of criteria was devised to make sure that that was the case.
We required that the potential productivity score with PL and NPL not be $0$ or $1$, which excluded many very rare words.
Furthermore, only N1s were used which had a minimal type frequency of $\Sexpr{n1asn1.typfreq.lim}$ as N1 with PL and NPL.
In order to exclude nouns which occur with reasonable type frequency in compounds but not much elsewehere, only N1s with a minimal token frequency outside of compounds were used.
To implement this restriction, we used the notion of the \textit{frequency class} (or \textit{frequency band}) of a word (see \citealt[80]{PerkuhnEa2012}).
The frequency class $c$ of a word $w$ increases with the word's token frequency $f_{token}(w)$, but calculation of the frequency class relates an individual word's token frequency to the frequency of the most frequent word in the corpus ($f_{token}^{max}$) as well as the power law distribution of word frequencies.%
\footnote{See \textcite{Piantadosi2014} for a recent overview, including the many problems with actual word frequency distributions.}
It is given by (\ref{eq:frequencyclass}).

\begin{equation}
  \label{eq:frequencyclass}
  c(w) = \left\lfloor{0.5 - log_2\left({\frac{f_{token}(w)}{f_{token}^{max}}}\right)}\right\rfloor
\end{equation}

The most frequent word in DECOW16A is \textit{und} `and' with $f_{token}(und)=\Sexpr{nice.int(decow16a.highest.f)}$.
Relative to this, we only considered words with a frequency class up to and including $\Sexpr{n1itself.tokfreq.lim}$, a class where, for example, \textit{Lid} `eyelid' ($f_{token}=\Sexpr{nice.int(analyses.full$er[which(analyses.full$er$N1 == "Lid"),"N1alone_Ftoken"])}$), \textit{Seilschaft} `rope team' ($f_{token}=\Sexpr{nice.int(analyses.full$en[which(analyses.full$en$N1 == "Seilschaft"),"N1alone_Ftoken"])}$), and \textit{Verlies} `oubliette' ($f_{token}=\Sexpr{nice.int(analyses.full$e[which(analyses.full$e$N1 == "Verlies"),"N1alone_Ftoken"])}$) are found.

From the set of N1s which fulfilled the given criteria, we sampled between five and ten per pluralic linking element.
Sampling was a manual process, and it was made sure that the nouns were countable (\ie no mass nouns), not collectives, and distributed approximately uniformly across the productivity spectrum as it was visualised in Figure~\ref{fig:proddots}.
In Figure~\ref{fig:corpusselection}, which is parallel to Figure~\ref{fig:proddots}, the small dots each represent an N1 which fulfils the selection criteria.
The triangles mark those which were actually chosen for the corpus study.
It is immediately obvious that the sample represents the overall spectrum of productivity quite well.

<<corpusselection, fig.pos="htb!", fig.height=8, fig.cap="Scatterplot of p-values">>=
par(mfrow=c(3,3))
for (le in prod.plot.order) {

  # Make blank space in plot.
  if (le == "EMPTY_PLOT") {
    plot.new()
    next
  }

  .le.name <- le.name(le)
  plot(corpus.candidates[[le]]$Without_Ppot ~ corpus.candidates[[le]]$With_Ppot,
       log="xy",
       pch = 20,
       cex = 1,
       col = "darkorange",
       xlim = c(0.001, 1),
       ylim = c(0.001, 1),
       main = paste0("Cand. for corpus study: ", .le.name),
       xlab = paste0("Productivity with ", .le.name),
       ylab = paste0("Productivity without ", .le.name)
  )
  .orig <- which(corpus.candidates[[le]]$N1 %in% corpus.items[[le]]$N1)
  points(corpus.candidates[[le]][.orig,]$Without_Ppot ~ corpus.candidates[[le]][.orig,]$With_Ppot,
         pch = 17,
         cex = 1.5,
         col = "darkgreen"
  )
}
par(mfrow=c(1,1))
@

The queries by which we retrieved the exemplars of compounds containing the chosen fifty N1s were made in DECOW16A using Python through the RStudio Server interface provided by the COW project.%
\footnote{See \url{https://www.webcorpora.org}.
The Python scripts showing the exact queries will be published openly as part of the data package for this paper.}
For each N1, we made one query searching for compounds containing it with PL and one (otherwise identical) query searching for compounds containing it with NPL.
Since at least some context is often needed to disambiguate the meaning of the compounds and their constituents, the whole sentence containing each compound as well as one sentence to the left and one sentence to the right were exported.
Duplicate sentences were removed by setting the appropriate parameter in the COW project's Python wrappers for making queries.
Additionally, we performed deduplication on the compounds inasmuch as we only allowed one instance of each compound word form to pass.
Otherwise, highly frequent and typically lexicalised compounds would have accounted for the best part of the concordances.
By allowing different word forms of the same compound into the concordances, however, singular and plural forms of the same compound might still be contained in it.
In addition to the literal exemplar in its context, we extracted the corresponding document URL, the unique COW16 ID of that document, and the sentence ID.
With the COW16 ID and the sentence ID, each exemplar can be located in the DECOW16A corpus for full reproducibility.
Finally, it should be noticed that we extracted all exemplars matching the query, making random sub-samples for annotation.%
\footnote{The full query results are also included in the data package which accompanies this paper.}

\subsection{Annotation}
\label{sec:annotation}

From each of the query results of the fifty N1s described in Section~\ref{sec:queries}, we annotated approximately one hundred cases with PL and one hundred with NPL.
Due to some minor cleanups in the quality control process, the final sample size is not exactly $n=10,000$ but $n=\Sexpr{nice.int(sum(t.plot$n))}$.

Annotating singular and plural was trivial, except where singular and plural forms were homographic \textit{and} the context did not help to disambiguate.
Such cases were diascarded and not used for the study.%\
\footnote{Since this part of the study is crucial and strongly related to the scientific inferences we are going to draw, we did not rely on the automatic annotation for plural (and other morphological categories) available in DECOW16A.
Furthermore, the basic annotations were made by the second author of this paper and a student assistant, but they were \textit{all} cross-checked by the first author, in order to minimise the amount of human annotation errors.}

Determining whether the semantics of N2 and the semantic relation holding between N1 and N2 forces N1 to have plural semantics was more intricate, and we found several classes of such N2s.
A clear case of plural-inducing N2s are collectives such as \textit{Gruppe} `group' as in \textit{Kindergruppe} `group of children' or \textit{Armee} `army' as in \textit{Bauernarmee} `army of peasants'.
Even metaphorical collectives are usually not problematic, for example \textit{Regen} `rain' in compounds like \textit{Zitateregen} `rain of quotations'.
Another major group are reciprocal such as \textit{Wechsel} `swap\slash exchange' as in \textit{Räderwechsel} `swapping of tyres'.
Similar to these are N2s such as \textit{Distanz} `distance' as in \textit{Lochdistanz} `distance between (the) holes', which were annotated as plural-inducing N2s if it became clear from the context that a distance \textit{between} several objects was referenced.
Many other types of N2s also required annotators to take the context into account.
Compounds with N2s like \textit{System} `system' as in \textit{Elementesystem} `system of elements\slash periodic system' were annotated as containing an N1 with a forced plural interpretation if the reading was clearly that of a `system of (several) elements'.

In addition to these clear-cut cases there was a second group of compounds in which the plural-inducing quality of the N2 was evemn more strongly context-dependent.
Most prominently, the N2 denotes a container of some sort.
Examples include \textit{Äpfellager} `storage for apples', \textit{Briefekatalog} `catalogue of letters', and \textit{Liederbuch} `book of songs\slash songbook'.
In essence, this second large group contains compounds where the N2 might theoretically denote a container etc.\ for just one object, both world knowledge and the context exclude this possibility beyond doubt.
In the analysis of the final sample we present the results for only the first, clear-cut cases and the results of both the clear-cut and the extended cases separately under le labels of \textit{strict annotation} (only the clear-cut cases) and \textit{lax annotation} (including extended cases).

\subsection{Results}
\label{sec:results}

\subsubsection{A statistical prelude}
\label{ssub:astatisticalprelude}

As stated in Section~\ref{sec:linkingelementsingerman}, we derived two operationalisable working hypotheses from our substantive hypothesis that there is a connection between pluralic links and plural interpretations of N1.
Before we turn to reporting the results, we now explain very briefly our position on data analysis and so-called \textit{hypothesis testing}.
The most widely used statistical system is \textit{Null Hypothesis Significance Testing} (NHST), and it is one of the \textit{frequentist} systems of statistical inference.
In NHST, researchers attempts to substantiate the existence of effects (such as a positive connection between plural semantics and pluralic linking elements), which is predicted to exist by some theory, by conducting experiments in which the effect is measured.
Then, the probabibility $p$ (the famous p-value) of obtaining the observed measurements or more extreme measurements is caculated under the assumption that there is actually \textit{no} effect (the \textit{null hypothesis} or just the \textit{null}).
If this probability is lower than a certain threshold (usually called the $\alpha$-\textit{level}), the null hypothesis is \textit{rejected}, which is taken as evidence that the hypothesis derived from the theory is correct.
It is often incorrectly stated that ``the experiment\slash test shows that the probability that the null is correct is $p$''.
This approach is riddled with conceptual problems and has led to the promotion of of bad scientific practice.
Among the most ardent critics are \textcite{Gigerenzer2004}, \textcite{Colquhoun2014}, and \textcite{MunafoEa2017}, and the editors of the journal \textit{Basic and Applied Social Psychology} have even banned the use of p-values in an actionist attempt to tackle problems of bad science related to NHST \parencite{TrafimowMarks2016}.
Critics often propose to abandon frequentist inference altogether and adopt a Bayesian approach, which itself is not without foundational and practical problems (see, for example, \citealt{Mayo1996}, \citealt{Senn2011}).
Other have proposed abandoning statistical inference proper in favour of confidence intervals and effect sizes \parencite{Cumming2014}, sometimes not noticing that NHST confidence intervals are not considerably different from NHST p-values, as \textcite{Perezgonzalez2015b} shows in reply to \textcite{Cumming2014}.

However, there is no need to abandon frequentism or p-values simply because they have been abused.
Many statisticians and researchers have shown that the major problem is that NHST is a mixture of the statistical philosophies of Ronald A. Fisher on the one hand and Jerzy Neyman and Egon Pearson on the other hand (see \citealt{Goodman2008}, \citealt{Perezgonzalez2014}, \citealt{Perezgonzalez2015}, \citealt{GreenlandEa2016}; see also \citealt{Lehmann1993} and \citealt{Lehmann2011} for an overview of these two philosophies and the history of their development).
Since we adopt Fisher's statistical philosophy, we briefly compare it to Neyman and Pearson's now.

Neyman and Pearson developed a system where two hypotheses which exhaust the probability space are specified, the \textit{main hypothesis} (H\Sub{M}) and the \textit{alternative hypothesis} (H\Sub{A}).
The goal is to accept either of these hypotheses, where typically H\Sub{M} is the hypothesis predicted by the theory favoured by the experimenter.
The reason why the Neyman-Pearson approach can be hard to implement is that H\Sub{M} needs to be precise with regard to the effect size.
For example, the experiment is a reading time experiment contrasting reading times under two distinct conditions, then the expected increase in reading times needs to specified numerically.
If this is possible, then researchers can calculate the risk of incorrectly accepting H\Sub{M} when it is actually false ($\alpha$) and the risk of incorrectly accepting H\Sub{A} when it is actually false ($\beta$) \textit{given specific sample sizes}, then setting the optimal sample size and choosing the optimal test procedure.
Especially Neyman designed this system explicitly with the idea in mind that researchers end up doing the right thing in $1-\alpha$ of all cases if they follow this protocol.
No inference with respect to the ultimate truth of a specific hypothesis at hand was ever intended by Neyman.
In empirical linguistics (both corpus-based and experimental), following the Neyman-Pearson protocol is often impossible because theories do not predict effect sizes.

Fisher developed a system where the probability of a specific outcome of a random experiment (or a more extreme outcome) \textit{if there is no effect} (the H\Sub{0} or \textit{null hypothesis} or simply the \textit{null}) is calculated as the p-value.
It cannot be stressed enough that this is the probability of obtaining such results \textit{before the experiment is conducted} and \textit{taking into account the design of the experiment}.
\textcite[504]{Fisher1926} suggests an informal, adaptive, and approximate \textit{threshold of significance} (or \textit{sig}), for example $0.05$, below which researcher might suspect that there is something going on (see also Section~4.4 in \citealt{Lehmann2011} for a detailed summary of Fisher's positions).
While Fisher did not directly recommend the inspection of p-values, he recommended that experimenters set \textit{sig} appropriately based on previous experimental or theoretical knowledge (see Chapter~4 of \citealt{Lehmann2011} and \citealt{Perezgonzalez2015}).
Furthermore, p-values can be corrected after the experiment, for examples if many conceptually related tests are performed, which increases the actual error rates relative to the nominal ones.
The most important pitfalls and misunderstandings (directly translating into some of the false assumptions common in NHST) in Fisher's framework are:

\vspace{\baselineskip}
\begin{enumerate}
  \item \label{it:fisher01} Researchrs take a significant result as a proof of something, usually the hypothesised effect.
    In fact, significance only shows that either the null does not describe the actual world well \textit{or a rare event has occured}.
  \item \label{it:fisher02} Practicitoners take point~(\ref{it:fisher01}) even further and make an inference from a single significant result to some substantive hypothesis such as ``my whole theory is correct''.
  \item \label{it:fisher03} Researchers assign high importance to some significant result although the data only suggests that the null might be rejected, but that the effect is rather small.
  \item \label{it:fisher04} If one runs a series of experiments and performs the corresponding tests in which the nulls are conceptually related, the actual probabilities of just a rare event happening increase, and each $p$ or the \textit{sig} level are too optimistic if left uncorrected.
  \item \label{it:fisher05} Finally, practitioners might not have conducted a proper random experiment (willfully or out of ignorance), thus changing the sample space and invalidating the actual computations
\end{enumerate}
\vspace{\baselineskip}

Points~(\ref{it:fisher01}) and~(\ref{it:fisher02}) can be remedied by researchers being aware of the actual (low) importance which should be attributed to a single significant result.
Furthermore, good use of previous experimental and theoretical knowledge in interpreting actual p-values (although Fisher himself was not much interested in interpreting p-values) helps in making the Fisher approach more sound in practice.
It also helps to do replications and perform meta-analyses.
Problem with point~(\ref{it:fisher03}) are easily avoided by looking at effect sizes (which are usually associated with the Neyman-Pearson approach, but imported easily into a Fisherian procedure), which is really just another way of saying that researchers should to proper exploratory analysis of their data sets.
Point~(\ref{it:fisher04}) can be dealt with by applying corrections for group-wise error (which should not be called ``$\alpha$-level correction'' under Fisher's approach).

Point~(\ref{it:fisher05}) poses the most serious threat to the validity in corpus linguistics.
Fisher's logic of experimental design presupposes that test subjects were randomly chosen from the population of interest and that confounding factors are thus distributed randomly (see Chapter~2 of \citealt{MaxwellDelaney2004} for a convenient overview).
Experimentation in corpus linguistics but also in linguistics in general is marred by the fact that researchers often cannot specify their population of interest with high precision.
The traditional discussion of the \textit{representativeness} of a corpus does not help because it is more often than not centered around the concept of a corpus being ``representative of a language'' (as a whole), using as points of reference:
(i) the distribution of texts or text types in the output of all speakers of a language (production-based),
(ii) the distribution of the relevance of texts or text types in the whole speech community (relevance-based), or
(iii) the distribution of the exposition events of speakers to different texts or text types (perception-based).%
\footnote{For overviews from different perspectives, see \textcite{Biber1993}, \textcite{MceneryEa2006}, \textcite{Leech2007}, \textcite{Hunston2008}.}
Even in \textcite{StefanowitschFlach2016}, a recent contribution where the perception-based view is argued to be a valid view in cognitively oriented approaches to language, a global view of representativity is addressed.%
\footnote{``In this wider context, large, register-mixed corpora such as the British National Corpus [\ldots] may not be perfect models of the linguistic experience of adult speakers, but they are reasonably close to the input of an idealized average member of the relevant speech community.'' \parencite[104]{StefanowitschFlach2016}}
The population of interest has to be defined with regard to each experiment individually, and it might be something very specific (such as the written output of speakers of a certain age, in a specific register, etc.) instead of ``the language'' or ``the average speaker'' (across all communicative settings and modes).
In social sciences, the concepts of \textit{global and specific representativeness} \citep[86]{Bortz2005} are used to describe the relevant distinction.
What corpus linguists usually do is draw convenience samples from whichever corpus is available, also because the hypotheses and theories which serve as the background for the experiment are not highly specific.
Such an approach is by no means wrong per se, and we include our own work in the same category.
However, we suggest that researchers should be aware of the problems and try to minimise the problems involved.
In ``global'' corpus studies, in order to alleviate the problems of potential non-random sampling, practitioners should
(i) choose the most varied and large corpus available,
(ii) regard their work as partly exploratory, even if statistical tests and previous theoretical knowledge (including predictions derived from theories) are used,
(iii) be appropriately careful in their interpretation of the findings, ideally using additional sources of data such as experiments (see \citealt{BresnanEa2007} for pioneering work in this area).

This is why we chose DECOW16A: it is very large but also contains a lot of variation (including non-standard writing).
Also, as we show below, we consider the exploratory nature of our work more important than binary decisions of significance.
Furthermore, we do not claim that our results generalise beyond the type of texts contained in DECOW16A, especially not to spoken language.
What is more, as will be shown in Section~\ref{sec:externalandinternalplurals}, careful data analysis reveals more fine-grained effects than audacious global hypothesis testing.
Finally, the experimental results reported in Section~\ref{sec:split100experiment} are shown to be much clearer than the corpus findings, which highlights the need to use corroborating evidence from several methods.

\subsubsection{External and internal plurals}
\label{sec:externalandinternalplurals}

<<differenceplcoll, fig.pos="htb!", fig.height=8, fig.cap="Distribution of signed Cramérs v scores for the number condition and the plural-inducing condition">>=
plot(x=NULL, y=NULL,
     xlim = c(0.5, 1.5),
     ylim=c(-0.5, 0.6),
     type="n", ann=FALSE, axes=F)
axis(1, at=c(0.85, 1.15), tick = F,
     labels=c("Ext. plural", "Int. plural"))
axis(2)
abline(h = 0, lwd = 2, lty = 2, col = "darkgray")
vioplot2(p.plot$phi,
         frame = F,
         at = 1,
         side = "left",
         col = "gold",
         add = T)
vioplot2(t.plot$phi.lax,
         at = 1,
         side = "right",
         col = "white",
         add = T)
vioplot2(t.plot$phi.strict,
         at = 1,
         side = "right",
         col = "orange",
         add = T)
title("Signed effect strengths\nin the two plural conditions",
      xlab = "Condition")
legend("bottomright", fill = c("white", "orange"),
       legend = c("lax anno.", "strict anno."),
       box.lty=0,
       cex = 1)
@

<<corpuseffects, fig.pos="htb!", fig.height=10, fig.cap="Scatterplot of p-values">>=
corpuseffects.colors <- colorRampPalette(c("orange", "darkgreen"))(100)

# The dots are in fact invisible (pch="") so we can draw freely later.
dotchart(t.plot$phi.strict,
         xlim=c(-0.2, +0.6),
         labels = t.plot$lemma,
         pch = "",
         cex=0.75,
         cex.axis = 5,
         gcolor = "black",
         groups = t.plot$link,
         color = unlist(lapply(t.plot$p.sidak.strict, function(x) map.my.ramp(x, corpuseffects.colors))),
         main = "Signed effect strength for the use of N1 with\npluralic linking element if N2 favours plural semantics on N1",
         xlab=paste0("Cramer's phi (signed) derived from bootstrapped Chi-square (", num.reps, " repititions)")
         ,sub = paste0("[Note: p-values for colour-coding were corrected for GWE (m=", nrow(t.plot) ,") using Sidak's method.]")
         )

abline(v = seq(-0.2, 0.6, 0.2), col = "lightgray", lty = 1, lwd=1)

# Now add first level to dotchart on top of verticl lines.
# Unfortunately not supported by built-in function.
this.y <- 1
for (l in rev(levels(t.plot$link))) {

  .t.subplot <- t.plot[which(t.plot$link == l),]
  for (n1 in 1:nrow(.t.subplot)) {
    points(.t.subplot[n1, "phi.strict"], this.y,
           pch = 16,
           col = map.my.ramp(.t.subplot$p.sidak.strict[n1], corpuseffects.colors)
    )
    this.y <- this.y + 1
  }
  this.y <- this.y + 2
}

# Now add second level to dotchart. Unfortunately not supported by built-in function.
this.y <- 1
for (l in rev(levels(t.plot$link))) {

  .t.subplot <- t.plot[which(t.plot$link == l),]
  for (n1 in 1:nrow(.t.subplot)) {
    points(.t.subplot[n1, "phi.lax"], this.y,
           pch = 1,
           cex = 1.7,
           col = map.my.ramp(.t.subplot$p.sidak.lax[n1], corpuseffects.colors)
    )
    this.y <- this.y + 1
  }
  this.y <- this.y + 2
}


legend("right", title = "p-values",
       legend = c("0", "0.05", "0.1", "0.5", "1"),
       col = c(corpuseffects.colors[100], corpuseffects.colors[65], corpuseffects.colors[50], corpuseffects.colors[16], corpuseffects.colors[1]),
       pch=19, bg = "white",
       cex = 1.0
       )
legend("bottomright",
      legend = c("strict", "lax"),
      title = "Annotation",
      bg = "white",
      pch = c(16,1),
      cex = 1.0
      )
@














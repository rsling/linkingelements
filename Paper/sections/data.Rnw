% !Rnw root = ../leglossa.Rnw
<<setupdata, cache=FALSE, include=FALSE, results='asis'>>=
opts_knit$set(self.contained=FALSE)
@

\section{Data}
\label{sec:data}

\subsection{Corpus choice}
\label{sec:corpuschoice}

\subsection{Database and productivity assessment}
\label{sec:databaseandproductivityassessment}

For the studies reported in Section~\ref{sec:corpusstudy} and~\ref{sec:split100experiment}, we had to choose a set of first constituents (N1s) to be examined more thoroughly using corpus data and a set of compounds to be used as stimuli in the split-100 experiment.
However, the total number of candidates for first constituents and compounds is quite high (from thousands to tens of thousands), and in order to make an informed selection, data about the type frequencies, token frequencies, and the productivity of first constituents were required.
This information tells us how stronlgy first constituents tend to appear pluralic linking elements and with non-pluralic links.
This section describes the creation of these data.

We began by extracting a very large database of all nominal compounds (not just N+N compounds) from the DECOW16A web corpus \parencite{SchaeferBildhauer2018}.%
\footnote{In agreement with the creators of the DECOW16A corpus, our database, which contains comprehensive aggregated information about the 22,380,133 compound types accounting for 478,342,305 tokens in the corpus, will be made publicly available.}
In the corpus, nominal compounds come with full structural analyses created automatically using the SMOR finite-state morphological analyser \parencite{SchmidEa2004} and extensive pre- and prost-processing implemented by the COW creators \parencite{SchaeferBildhauer2018}.%
\footnote{The analyses are formatted like \texttt{Zeit\_Punkt} for \textit{Zeitpunkt} `point in time\slash moment' (literally `time point') or \texttt{Wort\_+=er\_Buch} for \textit{WÃ¶rterbuch} `dictionary' (literally `word book').
Underscores separate the constituents of the compound, the nominal elements are given in their base form, and linking elements begin with \texttt{+} followed by a \texttt{=} if the linking element triggers stem umlaut on the first constituent.}
While we noticed that the automatic analyser (like all automatic annotation tools) makes some errors and sometimes fails in disambiguating some ambiguous compounds, it also became clear that the quality of analysis is more than sufficient for the kind of large-scale pre-analaysis we performed.
What is more, at each step of the analysis, we made sure through manual checks that the data which we actually used for the studies were clean.

<<>>=
aggregate.le <- function(df) {
  list(
    n1s       = nrow(df),
    types.w   = sum(df$With_Ftype),
    types.wo  = sum(df$Without_Ftype)
  )
}
le.aggregated <- sapply(analyses.full, aggregate.le)
colnames(le.aggregated) <- unname(sapply(colnames(le.aggregated), le.name))
rownames(le.aggregated) <- c("N1 types", "N1+N2 types: PL", "N1+N2 types: NPL")
@

First of all, as argued for in Section~\ref{sec:linkingelementsingerman}, we restrict our study to N+N compounds.
We therefore extracted all N+N compounds and all first constituents (N1s) from the large compound database.
For each of the pluralic linking elements (PL), we generated exhaustive lists of the N1s occuring with it which fulfil the criteria mentioned in Section~\ref{sec:linkingelementsingerman} (prominently: no mass nouns, no weak masculine nouns).%
\footnote{The lists of these N1s were extracted automatically but were checked for erroneous entries manually.
Both the first author of this paper and a student assistant checked the entire list in order to increase the precision of the manual clean up process.}
In total, we found \Sexpr{nice.int(sum(unlist(le.aggregated[1,])))} different N1s which are used with a PL.
Then, for each N1 we counted the numbers of compound types containing it, the number of compound tokens containing it, and the number of compound hapax legomena containing it (\ie those compounds containing the N1 which occur only once in the corpus).
Since we are interested in the alternation between N1s used with PLs and without them (either without any linking element, with deletion, or with a non-pluralic linking element such as \textit{-s}), we also extracted the same counts for the N1s in compounds with a non-pluralic link (NPL).

As explained in Section~\ref{sec:linkingelementsingerman}, the classes of words with the plural morphemes \textit{=er}, \textit{-er}, and \textit{=} are rather small with \Sexpr{nice.int(unlist(le.aggregated[1, "=er"]))}, \Sexpr{nice.int(unlist(le.aggregated[1, "-er"]))} and \Sexpr{nice.int(unlist(le.aggregated[1, "="]))} different N1 types, respectively.
While \textit{=e} has an intermediate type frequency of \Sexpr{nice.int(unlist(le.aggregated[1, "=e"]))}, \textit{-n} (\Sexpr{nice.int(unlist(le.aggregated[1, "-n"]))} types), \textit{-en} (\Sexpr{nice.int(unlist(le.aggregated[1, "-en"]))} types), and \textit{-e} (\Sexpr{nice.int(unlist(le.aggregated[1, "-e"]))} types) are highly type-frequent.
To be clear, we look at first constituents which at least sometimes occur with a pluralic linking element, but we also generate the relevant counts for these first constituents appearing with a non-pluralic link as basic information about item-specific tendencies in the alternation.

While the type and token frequencies of N1s with PL and NPL are informative, a comparison of their productivity with PL and NPL is equally important for making decisions regarding the corpus sample and selection of stimuli.
Therefore, we calculated measures of productivity for each N1 with PL and NPL.
This measure was supposed to capture the probability that the given N1 would form a new compound with PL and NPL.
The \textit{potential productivity} is the measure of choice for this as it ``gauges the extent to which the market for a category is saturated'' \parencite[902, see also 906--907]{Baayen2009}.
The potential productivity is appropriate for our purpose because some or even many compounds might be lexicalised either with PL or with NPL, and it would not make much sense to examine an alternation with N1s which occur mostly in lexicalised compounds.
As specified in (\ref{eq:prod}), the potential productivity $P^p$ is simply the number of the hapax legomena ($f_1$) of compounds with $\mathrm{N1}_{le}$ divided by the token frequency ($f$) of compounds with $\mathrm{N1}_{le}$, where $le$ stands for either PL or NPL.

\begin{equation}\label{eq:prod}
P^p(\mathrm{N1}_{le})=\frac{f_1(\mathrm{N1}_{le})}{f(\mathrm{N1}_{le})}
\end{equation}

The interpretation of $P^p$ is intuitive, as it is $0$ when there is not a single hapax legomenon in the corpus (no productivity whatsoever), and it is $1$ if all tokens are hapax legomena (maximal productivity).
It can be regarded as a proportion, and its range is therefore $[0,1]$.

% For final production, remove this figure and re-activate knitr proddots block.
\begin{figure}
\begin{center}
    \includegraphics[scale=]{images/proddots_tmp}
\end{center}
\caption{Comparisons of the potential productivity ($P^p$) of first constituents, grouped by their PL; colors and sizes encode the type frequencies with PL and NPL}
\label{fig:proddots}
\end{figure}


<<proddots, fig.pos="htbp", fig.height=8, fig.cap="Comparisons of the potential productivity of N1s, grouped by linking elements; colours and sizes encode the type frequencies with PL and NPL; axes are on a logarithmic scale">>=
productivitydots.colors <- colorRampPalette(c("gold", "darkred"))(100)
# par(mfrow=c(3,3))
.args <- list(analyses      = analyses.full,
              dots          = T,
              max.plottable = -1,
              norm.xax      = c(10^-3, 1),
              norm.yax      = c(10^-3, 2),
              zero.floor    = NULL,
              the.colors    = productivitydots.colors,
              main.chunk = "",
              ylab.chunk = "Productivity with NPL",
              xlab.chunk = "Productivity with PL")
# for (le in prod.plot.order)
#   do.call(plot.productivities, c(list(le = le), .args))
# par(mfrow=c(1,1))
@

Figure~\ref{fig:proddots} shows the results of the productivity analyses for all chosen N1s.%
\footnote{It was pointed out that the analysis of productivity is tainted by the low quality of automatic annotation in \textcite{EvertLuedeling2001} -- a point reiterated in \textcite[907]{Baayen2009}.
Our analysis relies on the automatically generated annotaions by the SMOR tool and COW tool chain.
However, the list of N1 candidates was meticulously cleaned manually, as stated above.
Also, we have found that the compound analyses by the SMOR tool are highly accurate when it does not have to guess the lemma of a compound's elements, and the N1s actually used are obviously known words.
Finally, the N1s which were chosen for the studies presented in Sections~\ref{sec:corpusstudy} and~\ref{sec:split100experiment} were manually checked again.
In the annotation of the \Sexpr{nice.int(sum(t.plot$n))} corpus exemplars, any systematic misanalysis would have shown.
This actually happened for the N1 \textit{Beere} `berry', where the concordance for NPL contained mostly erroneously analysed words and proper names, and \textit{Beere} was subsequently excluded from further steps.
We can thus be sure that the analyses which we interpret relative to our theoretical hypotheses are accurate and not distorted by problems of automatic annotation.
}
In this plot, each dot represents one N1.
Its position is determined by its $P^p$ value with PL (x-axis) and with NPL (y-axis).
Additionally, the larger a dot is, the higher is its type frequency with PL, and the darker it is, the higher is its type frequency with NPL.
From the panels for \textit{-n} and \mbox{\textit{-en}}, it is apparent that N1s with all sorts of ratios of high and low productivity with PL and NPL exist.
The tendency for dots to be smaller towards the right-hand side (high productivity with PL) and lighter towards to top (higher productivity with NPL) is explained by the fact that a lower overall type frequency makes it more likely that the productivity score is high.
In the extreme case, a N1 has a type frequency of $1$, and there is only one occurrence of it (one hapax legomenon), which results in a potential productivity score of $1$.
Since the \textit{-n} and \textit{-en} plurals are often used with rare loan words, there are many items with low type frequency and a high productivity score.
Examples include \textit{Ikonostase} (pl.\ \textit{Ikonostasen}) `iconostasis', which has a token frequency of $\Sexpr{analyses.full$n[which(analyses.full$n$N1 == "Ikonostase"),"With_Ftype"]}$ and a hapax count of $\Sexpr{analyses.full$n[which(analyses.full$n$N1 == "Ikonostase"),"With_Fhapax"]}$ with PL (thus a potential productivity of $\Sexpr{analyses.full$n[which(analyses.full$n$N1 == "Ikonostase"),"With_Ppot"]}$) and \textit{Testator} (pl. \textit{Testatoren}) `testator' with a token frequency of $\Sexpr{analyses.full$en[which(analyses.full$en$N1 == "Testator"),"With_Ftype"]}$ and a hapax count of $\Sexpr{analyses.full$en[which(analyses.full$en$N1 == "Testator"),"With_Fhapax"]}$ with PL (thus also a potential productivity of $\Sexpr{analyses.full$en[which(analyses.full$en$N1 == "Testator"),"With_Ppot"]}$).

For N1s with \textit{-e} and \textit{=w}, and even more so for those with \textit{=er}, \textit{-er}, and \textit{=}, the overall pattern seems to be that the productivitiy scores with PL are spread out between $0$ and $1$.
However, there are virtually no N1s in these classes which show a very high productivity (much higher than $0.1$) with NPL.
The type frequencies are, however, still quite high for both PL and NPL, as reflected in the colour and the size of the dots.
For \textit{=er}, for example, the 25th and 75th percentiles of the token frequencies with PL are at \Sexpr{nice.int(quantile(analyses.full$Uer$With_Ftype, probs = 0.25))} and \Sexpr{nice.int(quantile(analyses.full$Uer$With_Ftype, probs = 0.75))} types, respectively.
With NPL, they are at \Sexpr{nice.int(quantile(analyses.full$Uer$Without_Ftype, probs = 0.25))} and \Sexpr{nice.int(quantile(analyses.full$Uer$Without_Ftype, probs = 0.75))} types.
In Sections~\ref{sec:corpusstudy} and~\ref{sec:split100experiment}, we use the data described here to create informed selections of items for further study.

% !Rnw root = ../leglossa.Rnw
<<setupdata, cache=FALSE, include=FALSE, results='asis'>>=
opts_knit$set(self.contained=FALSE)
@

\section{Data}
\label{sec:data}

\subsection{Corpus choice}
\label{sec:corpuschoice}

We chose the web-crawled DECOW16A corpus (\citealt{SchaeferBildhauer2012a}, \citealt{SchaeferBildhauer2018}) for all our corpus work.%
\footnote{See \url{http://corporafromtheweb.org/} for project information and \url{https://www.webcorpora.org/} for access to the corpora.}
This corpus was the obvious choice for several reasons.
First of all, it is available in an on-line query interface but also for scripted access and (in sentence-wise shuffled form) for download.%
\footnote{It is also available free of charge to anyone working in the academia.
The same is also true for the English ENCOW16A ($16.5$ billion tokens), the French FRCOW16A ($10.8$ billion tokens). the Spanish ESCOW16A ($7.1$ billion tokens), as well as the older Swedish SVCOW14A (8.4 billion tokens) and Dutch NLCOW14A (6.7 billion tokens).}
The large-scale productivity assessment to be reported in Section~\ref{sec:databaseandproductivityassessment} would not have been possible without scripted access.
More importantly, using large amounts of recently produced data, including data not written under strong normative pressure (such as forums and other community websites) is in our view ideal for research on productive processes from a synchronic perspective (be it descriptive, geared towards competence grammar, or cognitively oriented).
The only other available very large corpus containing recent German would be the \textit{Deutsches Refernzkorpus} (DeReKo) by the \textit{Institut für Deutsche Sprache} \parencite{KupietzEa2010}, but as of today it is not available for scripted access, and it mostly contains newspaper text.
Finally, the COW corpora are based on an improved methodology also used to build the WaCky corpora \parencite{BaroniEa2009}, and there are other similar web-derived corpora also actively used by many linguists, such as the SketchEngine corpora \parencite{KilgarriffEa2014}.
Web corpora can thus be regarded as an established source of data on a par with traditionally compiled corpora.

\subsection{Database and productivity assessment}
\label{sec:databaseandproductivityassessment}

For the studies reported in Section~\ref{sec:corpusstudy} and~\ref{sec:split100experiment}, we had to choose a set of first constituents (N1s) to be examined more thoroughly using corpus data and a set of compounds to be used as stimuli in the split-100 experiment.
The total number of candidates for first constituents and compounds is quite high (from thousands to tens of thousands), and in order to make an informed selection, large-scale data about the type frequencies, token frequencies, and the productivity of first constituents were required.
We used automatic approaches to create a set of databases, and demanding manual clean-up and selection steps in-between automatic steps were used to ensure that the results were reliable.
The database tells us how strongly first constituents tend to appear with PLs and with NPLs, including an assessment of their productivity with these linkages.
This section describes the creation of the database.

<<>>=
aggregate.freqs <- function(fto, fty, ns, le) {
  list(
    Ftype  = sum(fty[[le]]$F),
    Ftoken = sum(fto[[le]]$F),
    N1s    = nrow(ns[[le]])
  )
}
freq.ov <- t(sapply(tail(names(ftoken), -1), function(le) {aggregate.freqs(ftoken.lax, ftype.lax, nouns.lax, le)}))
rownames(freq.ov) <- le.name(rownames(freq.ov))
freq.ov <- as.data.frame(freq.ov)

freq.ov$Ftype    <- as.numeric(freq.ov$Ftype)
freq.ov$FtypePc  <- freq.ov$Ftype / sum(freq.ov$Ftype) * 100
freq.ov$Ftoken   <- as.numeric(freq.ov$Ftoken)
freq.ov$FtokenPc <- freq.ov$Ftoken / sum(freq.ov$Ftoken) * 100
freq.ov$N1s      <- as.numeric(freq.ov$N1s)
freq.ov$N1sPc    <- freq.ov$N1s / sum(freq.ov$N1s) * 100

freq.ov <- freq.ov[order(freq.ov$Ftype, decreasing = T),]
@

We began by extracting a very large database of all nominal compounds (not just N1+N2 compounds but any compound with a nominal head) from the DECOW16A web corpus (\citealt{SchaeferBildhauer2012a}, \citealt{SchaeferBildhauer2018}).%
\footnote{In agreement with the creators of the DECOW16A corpus, our database, which contains comprehensive aggregated information about the 22,380,133 compound types accounting for 478,342,305 tokens in the corpus, will be made publicly available.}
In the corpus, nominal compounds come with full structural analyses created automatically using the SMOR finite-state morphological analyser \parencite{SchmidEa2004} and extensive pre- and post-processing implemented by the COW creators \parencite{SchaeferBildhauer2018}.%
\footnote{The analyses are formatted as \texttt{Zeit\_Punkt} for \textit{Zeitpunkt} `point in time\slash moment' (literally `time point') or \texttt{Wort\_+=er\_Buch} for \textit{Wörterbuch} `dictionary' (literally `word book').
Underscores separate the constituents of the compound, the nominal elements are given in their base form, and LEs begin with \texttt{+} followed by a \texttt{=} if the LE triggers stem umlaut on the first constituent.}
While we noticed that the automatic analyser (like all automatic annotation tools) makes some errors and sometimes fails in disambiguating ambiguous compounds, it also became clear that the quality of analysis is more than sufficient for the kind of large-scale pre-analysis we performed.
More importantly, at each step of the analysis, we made sure through manual checks that the data which we actually used for the studies were clean.%
\footnote{We made an exception for the zero linkage because the number of N1s was much too high for full manual inspection.
We therefore implemented an automatic approach where a N1 had to fulfil one of the following criteria to be included:
(i) It was a word known to the aspell spell checker (in the mixed capitalisation typical of German nouns) and not in the list of proper nouns extracted from the DECOW corpus published by the COW project.
(ii) It occurred at least $50$ times in DECOW16A in mixed capitalisation spelling and was not in the list of proper nouns.
These criteria led to $\Sexpr{nice.int(nrow(blacklists$nul))}$ of $\Sexpr{nice.int(freq.ov["0","N1s"]+nrow(blacklists$nul))}$ nouns being excluded from the list of zero linkage N1 candidates.}

<<results='asis'>>=

freq.ov["$\\Sigma$", ] <- apply(freq.ov, 2, sum)
freq.ov$Ftype    <- nice.int(freq.ov$Ftype)
freq.ov$FtypePc  <- nice.float(freq.ov$FtypePc)
freq.ov$Ftoken   <- nice.int(freq.ov$Ftoken)
freq.ov$FtokenPc <- nice.float(freq.ov$FtokenPc)
freq.ov$N1s      <- nice.int(freq.ov$N1s)
freq.ov$N1sPc    <- nice.float(freq.ov$N1sPc)

freq.ov <- freq.ov[,c("Ftype", "FtypePc", "Ftoken", "FtokenPc", "N1s", "N1sPc")]
colnames(freq.ov) <- c("Compound $F$", "\\%", "Compound $f$", "\\%", "N1 $F$", "\\%")
rownames(freq.ov)[1] <- "$\\varnothing$"

freq.ov.xt <- xtable(
  freq.ov,
  booktabs = T,
  caption = "Type and token frequencies of all linkages in N1+N2 compounds in DECOW16A",
  label = "tab:freqoverview"
)
align(freq.ov.xt) <- c("l", rep("r", 6))
print(freq.ov.xt,
      floating = T,
      table.placement = 'htbp',
      booktabs = T,
      rotate.colnames = F,
      hline.after = c(-1,0,12,13),
      sanitize.text.function = function(x){x}
)
@

<<>>=
aggregate.le <- function(df) {
  list(
    n1s       = nrow(df),
    types.w   = sum(df$With_Ftype),
    types.wo  = sum(df$Without_Ftype)
  )
}
le.aggregated <- sapply(analyses.full, aggregate.le)
colnames(le.aggregated) <- unname(sapply(colnames(le.aggregated), le.name))
rownames(le.aggregated) <- c("N1 types", "N1+N2 types: PL", "N1+N2 types: NPL")
@

First of all, as argued for in Section~\ref{sec:linkingelementsingerman}, we restrict our study to N1+N2 compounds.
We therefore extracted all N1+N2 compounds and all first constituents (N1s) from the large compound database.
For each of the pluralic linkages (PL), we generated exhaustive lists of the N1s with which it occurs which have a plural identical to the PL (to exclude the few cases where a potentially PL attaches to a noun of a different declension class), are count nouns (because mass nouns undergo a significant change in meaning when pluralised), are not weak masculine nouns (because these do not differentiate between singular non-nominative forms and plural forms).
The lists of N1 candidates were extracted automatically, but they were checked for the aforementioned criteria and sporadic results of incorrect automatic analysis manually.
Both the first author of this paper and a student assistant checked the entire list in order to increase the accuracy of the manual clean up process.%
\footnote{Every single decision is documented in the data package for this paper.}
When an N1 candidate looked suspicious, we inspected the compound database to check whether the actual compounds containing the candidate were misanalysed or otherwise noisy.

In total, we found \Sexpr{nice.int(sum(unlist(le.aggregated[1,])))} different N1s which are used with a PL.
Then, for each N1 we counted the numbers of compound types, the number of compound tokens, and the number of compound hapax legomena (\ie those compounds containing the N1 which occur only once in the corpus) containing it.
Since we are interested in the alternation between N1s used with PLs and without them (either without any LE, with deletion, or with a non-pluralic LE such as \textit{-s}), we also extracted the same counts for the N1s in compounds with a non-pluralic linkage (NPL).
An overview of the type frequencies ($F$) and token frequencies ($f$) of the different linkages in DECOW16A is given in Table \ref{tab:freqoverview}.%
\footnote{In these counts, mass nouns and weak nouns were included in order to provide a complete overview.
Since they were removed for all further analysis reported below, the frequencies in the table are higher, especially for \textit{-n} and \textit{-en}, which are the hypothetical PLs of the weak nouns.}
The numbers are approximately in line with previous reports based on much smaller corpora such as \textcite{WellmannEa1974}, \textcite{Kuerschner2005}, or \textcite{KrottEa2007} (see also \citealt[9]{Schluecker2012}).
As explained in Section~\ref{sec:linkingelementsingerman}, the classes of words with the plural morphemes \textit{=er}, \textit{-er}, and \textit{=} are rather small with \Sexpr{nice.int(unlist(le.aggregated[1, "=er"]))}, \Sexpr{nice.int(unlist(le.aggregated[1, "-er"]))} and \Sexpr{nice.int(unlist(le.aggregated[1, "="]))} different N1 types in our database, respectively.
While \textit{=e} has an intermediate type frequency of \Sexpr{nice.int(unlist(le.aggregated[1, "=e"]))}, \textit{-n} (\Sexpr{nice.int(unlist(le.aggregated[1, "-n"]))} types), \textit{-en} (\Sexpr{nice.int(unlist(le.aggregated[1, "-en"]))} types), and \textit{-e} (\Sexpr{nice.int(unlist(le.aggregated[1, "-e"]))} types) are highly type-frequent.

Readers should keep in mind that we searched for N1s which at least sometimes occur with a PL, but we also generated the relevant counts for these first constituents appearing with a NPL.
While raw type and token frequencies are informative to some extent, a comparison of their productivity with PL and NPL is equally important for making decisions regarding the corpus sample and selection of stimuli.
Therefore, we calculated measures of productivity for each N1 with PL and NPL.
This measure was supposed to capture the probability that the given N1 would form a new compound with PL and NPL.
The \textit{potential productivity} is the measure of choice for this as it ``gauges the extent to which the market for a category is saturated'' \parencite[902, see also 906--907]{Baayen2009}.
The potential productivity is appropriate for our purposes because some or even many compounds might be lexicalised either with PL or with NPL, and it would not make much sense to try to examine an alternation with N1s which occur mostly in lexicalised compounds.
As shown in (\ref{eq:prod}), the potential productivity $P^p$ is simply the number of the hapax legomena ($f_1$) of compounds with $\mathrm{N1}_{le}$ divided by the token frequency ($f$) of compounds with $\mathrm{N1}_{le}$, where $le$ stands for either PL or NPL.

\begin{equation}\label{eq:prod}
P^p(\mathrm{N1}_{le})=\frac{f_1(\mathrm{N1}_{le})}{f(\mathrm{N1}_{le})}
\end{equation}

The interpretation of $P^p$ is intuitive, as it is $0$ when there are no hapax legomena in the corpus ($f_1(\mathrm{N1})_{le}=0$; no productivity whatsoever), and it is $1$ if all tokens are hapax legomena ($f_1(\mathrm{N1})_{le}=f(\mathrm{N1})_{le}$; maximal productivity).
It can be regarded as a proportion, and its range is therefore $[0,1]$.

%%% ==================================================================== %%%
%%% IMPORTANT! For production, PNG/PDF should be changed in chunk below. %%%
%%% ==================================================================== %%%

<<proddots, pdf=TRUE, fig.pos="htbp", fig.height=8, fig.cap="Comparisons of the potential productivity of N1s, grouped by PLs; colours and sizes encode the type frequencies with PL and NPL; axes are on a logarithmic scale">>=
productivitydots.colors <- colorRampPalette(c("gold", "darkred"))(100)
par(mfrow=c(3,3))
.args <- list(analyses      = analyses.full,
              dots          = T,
              max.plottable = -1,
              norm.xax      = c(10^-3, 1),
              norm.yax      = c(10^-3, 2),
              zero.floor    = NULL,
              the.colors    = productivitydots.colors,
              main.chunk = "",
              ylab.chunk = "Productivity with NPL",
              xlab.chunk = "Productivity with PL")
for (le in prod.plot.order)
 do.call(plot.productivities, c(list(le = le), .args))
par(mfrow=c(1,1))
@

Figure~\ref{fig:proddots} shows the results of the productivity analyses for all chosen N1s.%
\footnote{It was pointed out that the analysis of productivity is tainted by the low quality of automatic annotation in \textcite{EvertLuedeling2001} -- a point reiterated in \textcite[907]{Baayen2009}.
Our analysis relies on the automatically generated annotations by the SMOR tool and COW tool chain.
However, the list of N1 candidates was meticulously cleaned manually, as stated above.
Also, we have found that the compound analyses by the SMOR tool are highly accurate when it does not have to guess the lemma of a compound's elements, and the N1s actually used are obviously known words.
Finally, the N1s which were chosen for the studies presented in Sections~\ref{sec:corpusstudy} and~\ref{sec:split100experiment} were manually checked again.
In the annotation of the \Sexpr{nice.int(sum(t.plot$n))} corpus exemplars, any systematic misanalysis would have shown.
This actually was the case for the N1 \textit{Beere} `berry', where the concordance for NPL contained mostly erroneously analysed words and proper names, and \textit{Beere} was subsequently excluded from further steps.
We can thus be sure that the analyses which we interpret relative to our theoretical hypotheses are accurate and not distorted by problems of automatic annotation.
}
In this plot, each dot represents one N1.
Its position is determined by its $P^p$ value with PL (x-axis) and with NPL (y-axis).
Additionally, the larger a dot is, the higher is its type frequency with PL, and the darker it is, the higher is its type frequency with NPL.
From the panels for \textit{-n} and \mbox{\textit{-en}}, it is apparent that N1s with all sorts of ratios of high and low productivity with PL and NPL exist.
The tendency for dots to be smaller towards the right-hand side (high productivity with PL) and lighter towards to top (higher productivity with NPL) is explained by the fact that a lower overall type frequency makes it is easier to achieve a high productivity score.
In the extreme case, a N1 has a type frequency of $1$, and there is only one occurrence of it (necessarily a hapax legomenon), which results in a potential productivity score of $1$.
Since the \textit{-n} and \textit{-en} plurals are often used with rare loan words, there are many items with low type frequency and a high productivity score.
Examples include \textit{Ikonostase} (pl.\ \textit{Ikonostasen}) `iconostasis', which has a token frequency and a hapax count of $\Sexpr{analyses.full$n[which(analyses.full$n$N1 == "Ikonostase"),"With_Fhapax"]}$ with PL (thus a potential productivity of $\Sexpr{analyses.full$n[which(analyses.full$n$N1 == "Ikonostase"),"With_Ppot"]}$) and \textit{Testator} (pl. \textit{Testatoren}) `testator' with a token frequency and a hapax count of $\Sexpr{analyses.full$en[which(analyses.full$en$N1 == "Testator"),"With_Fhapax"]}$ with PL (thus also a potential productivity of $\Sexpr{analyses.full$en[which(analyses.full$en$N1 == "Testator"),"With_Ppot"]}$).

For N1s with \textit{-e} and \textit{=e}, and even more so for those with \textit{=er}, \textit{-er}, and \textit{=}, the productivity scores with PL are spread out between $0$ and $1$.
However, there are virtually no N1s in these classes which show a very high productivity (much higher than $0.1$) with NPL.
The type frequencies are, however, still quite high for both PL and NPL, as reflected in the colour and the size of the dots.
For \textit{=er}, for example, the 25th and 75th percentiles of the token frequencies with PL are at \Sexpr{nice.int(quantile(analyses.full$Uer$With_Ftype, probs = 0.25))} and \Sexpr{nice.int(quantile(analyses.full$Uer$With_Ftype, probs = 0.75))} types, respectively.
With NPL, they are at \Sexpr{nice.int(quantile(analyses.full$Uer$Without_Ftype, probs = 0.25))} and \Sexpr{nice.int(quantile(analyses.full$Uer$Without_Ftype, probs = 0.75))} types.
In Sections~\ref{sec:corpusstudy} and~\ref{sec:split100experiment}, we use the data described here to make informed selections of items for further study and we also detail the studies performed with these items.
